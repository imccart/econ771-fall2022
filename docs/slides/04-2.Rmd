---
title: "Regression Discontinuity Extensions"
subtitle: "<html><div style='float:left'></div><hr color='#EB811B' size=1px width=0px></html>"
author: Ian McCarthy | Emory University
date: Econ 771, Fall 2022
header-includes: 
  - \usepackage{graphicx}
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{tikz}
  - \usepackage{pgf}
  - \usepackage{pgfarrows}
  - \usepackage{pgfnodes}
  - \usepackage{pgfautomata}
  - \usepackage{pgfheaps}
  - \usepackage[absolute,overlay]{textpos}  
  - \usepackage{mathtools}
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts, custom.css] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "macros.js"
bibliography: '../syllabus/BibTeX_Library.bib'      
---
class: inverse, center, middle



<!-- Adjust some CSS code for font size and maintain R code font size -->
<style type="text/css">
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code {
  font-size: 15px;
}
.remark-inline-code { 
    font-size: 20px;
}
</style>


<!-- Set R options for how code chunks are displayed and load packages -->
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
knitr::opts_chunk$set(
  fig.align="center",  
  fig.height=3, #fig.width=6,
  # out.width="748px", #out.length="520.75px",
  dpi=300, #fig.path='Figs/',
  cache=T,# echo=F, warning=F, message=F
  warning = FALSE, 
  message = FALSE, 
  cache.lazy = FALSE,
  error=TRUE
  )

knitr::opts_hooks$set(fig.callout = function(options) {
  if(options$fig.callout) {
    options$echo = FALSE
  }
  options
})

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, ggplot2, dplyr, lubridate, readr, readxl, fixest, readstata13,
               xaringanExtra, webshotm, ggthemes, gganimate, plotly, ivpack, ivreg)
set.seed(1234)
```

```{r xaringan-scribble, echo=FALSE}
xaringanExtra::use_scribble(rgb(0.9, 0.5, 0.5))
```


# RD with Discrete Running Variable

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>

---
# Discrete Running Variables

- Standard smoothness argument no longer applies
- Need to assume that observations are as good as randomly assigned above/below threshold



---
class: inverse, center, middle

# RD with Multiple Cutoffs

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
class: inverse, center, middle

# Regression Kink

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
class: inverse, center, middle

# Bias and Undersmoothing

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Asymptotic distribution

From Cattaneo et al. (2020):
$$\text{MSE}(\hat{\tau}_{SRD}) = \text{Bias}^{2}(\hat{\tau}_{SRD}) + \text{Var}(\hat{\tau}_{SRD}) = (h^{2(p+1)}\mathcal{B})^{2} + \frac{1}{nh}\mathcal{V}$$
- $p$ is the polynomial degree of the local linear estimator ($p=1$ for linear)
- $\mathcal{B}$ is the leading bias term of an expansion 
- $\mathcal{V}$ is the leading variance term


---
# Asymptotic distribution

Choice of $h$ that minimizes this MSE (conditional on $p$ and the kernel) is:
$$h_{MSE} = \left(\frac{\mathcal{V}}{2(p+1)\mathcal{B}^{2}}\right)^{1/(2p+3)}n^{-1/(2p+3)}$$

- for $p = 1$, $o(h_{MSE}) = n^{-1/5}$
- but choosing $h_{MSE} \propto  n^{-1/5}$ does not lead to zero bias because bias reduces to zero at slower rate


---
# Asymptotic distribution

- Calonico, Cattaneo, and Titunik (2015) argues for plug-in estimator for bias
- Idea: 
    - Estimate local RD estimate with quadratic terms
    - Use second derivative to approximate bias for the local linear RD
    - Adjust resulting local linear RD
- Calonico, Cattaneo, and Farrell (2020) argues for CE-optimal bandwidths